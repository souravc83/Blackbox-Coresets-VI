{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31750948-f8ca-4b74-b15c-2da74c5102d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/Blackbox-Coresets-VI\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4e270-d1d9-41d1-bb88-d4984e793e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e008e-76d9-4b7d-8d4f-9c6103c0da6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c0fcec-d78b-4871-8e02-cebff14f9151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093f694-af26-4e3d-a338-266a7afc08ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abbd394-1168-47cc-94bd-701371e6e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: move to requirements.txt, otherwise we need to do pip install .\n",
    "# for every change we make to the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1407ad70-2a5a-4190-84e2-570eb0be9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(\"/home/studio-lab-user/Blackbox-Coresets-VI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18255c1-8969-4a22-b300-0e28ecd5d053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6574b010-121a-4260-b64f-11f7862069f5",
   "metadata": {},
   "source": [
    "### MNIST Random Fixed U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7d34db-1c94-46ff-8753-1c175738740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
      "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.])\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.30%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 50%|█████████████████████▌                     | 10/20 [01:21<01:11,  7.13s/it]\n",
      "predictive accuracy: 67.94%\n",
      "100%|███████████████████████████████████████████| 20/20 [02:42<00:00,  8.11s/it]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 20 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata\\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0f6a39-4acd-4ec3-8207-8d941b2f6cf6",
   "metadata": {},
   "source": [
    "### MNIST Random Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acff58d-4072-44d4-a4d4-61700ac70b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
      "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.])\n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.37%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "100%|█████████████████████████████████████████████| 2/2 [02:07<00:00, 63.52s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py:1224: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 2 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved \\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067c8778-f8dc-4ddd-9a70-13c5beecaf3a",
   "metadata": {},
   "source": [
    "### MNIST Kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd36c6f-77bd-49ed-808f-f82dcbcee36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 80 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "Points from this cluster: [15814 29067 24105 32383]\n",
      "Points from this cluster: [50480  5298 49770 28357]\n",
      "Points from this cluster: [ 5507  3956  5235 57453]\n",
      "Points from this cluster: [38432 36682 38985  7574]\n",
      "Points from this cluster: [50575 42830 13491 10411]\n",
      "Points from this cluster: [19694 20550 58710  9472]\n",
      "Points from this cluster: [58760 10415  5542 54898]\n",
      "Points from this cluster: [ 7106 21420 31720 24119]\n",
      "Points from this cluster: [52260  4318 23713 21246]\n",
      "Points from this cluster: [28599  4549 18473 38286]\n",
      "Points from this cluster: [51874 34857 13796 32141]\n",
      "Points from this cluster: [ 5984 36579 14689 31982]\n",
      "Points from this cluster: [12980 44755  3043 14921]\n",
      "Points from this cluster: [ 2025 54200 13970 17023]\n",
      "Points from this cluster: [24571 26642 19929 51489]\n",
      "Points from this cluster: [20004 38920 48861 33393]\n",
      "Points from this cluster: [ 8951 30527 19201 18931]\n",
      "Points from this cluster: [13866 27072 39344 15149]\n",
      "Points from this cluster: [35188 13409 38899 17437]\n",
      "Points from this cluster: [29091  8199 35444 17410]\n",
      "Number of data points: 80\n",
      "Number of unique data points 80\n",
      "Chosen indices: [38985, 27072, 3956, 34857, 24119, 5984, 36579, 38899, 20550, 29091, 17410, 30527, 58710, 50575, 24105, 42830, 54200, 54898, 3043, 24571, 21420, 49770, 52260, 17023, 20004, 13796, 38432, 31720, 10411, 26642, 13491, 23713, 4549, 14689, 7106, 9472, 32383, 18473, 19201, 8951, 35444, 21246, 4318, 13866, 10415, 44755, 36682, 15149, 19694, 2025, 38286, 38920, 58760, 51874, 8199, 19929, 12980, 35188, 51489, 5235, 5507, 29067, 14921, 33393, 57453, 28599, 50480, 18931, 32141, 5542, 28357, 13970, 5298, 15814, 48861, 17437, 39344, 7574, 31982, 13409]\n",
      "tensor([1, 8, 1, 5, 3, 5, 5, 9, 2, 9, 9, 8, 2, 2, 0, 2, 6, 3, 6, 7, 3, 0, 4, 6,\n",
      "        7, 5, 1, 3, 2, 7, 2, 4, 4, 5, 3, 2, 0, 4, 8, 8, 9, 4, 4, 8, 3, 6, 1, 8,\n",
      "        2, 6, 4, 7, 3, 5, 9, 7, 6, 9, 7, 1, 1, 0, 6, 7, 1, 4, 0, 8, 5, 3, 0, 6,\n",
      "        0, 0, 7, 9, 8, 1, 5, 9])\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.49%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [03:55<32:18, 21.54s/it]\n",
      "predictive accuracy: 83.53%\n",
      " 20%|████████▍                                 | 20/100 [06:55<20:13, 15.17s/it]\n",
      "predictive accuracy: 84.37%\n",
      " 30%|████████████▌                             | 30/100 [09:44<18:28, 15.83s/it]\n",
      "predictive accuracy: 84.32%\n",
      " 40%|████████████████▊                         | 40/100 [12:34<16:20, 16.34s/it]\n",
      "predictive accuracy: 84.58%\n",
      " 50%|█████████████████████                     | 50/100 [15:04<11:46, 14.13s/it]\n",
      "predictive accuracy: 84.59%\n",
      " 60%|█████████████████████████▏                | 60/100 [17:55<10:15, 15.39s/it]\n",
      "predictive accuracy: 84.45%\n",
      " 67%|████████████████████████████▏             | 67/100 [19:47<08:02, 14.62s/it]"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 80 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3810c3-71f7-41cd-b7f5-d91d0008f918",
   "metadata": {},
   "source": [
    "### CIFAR Resnet Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e398f8f7-2c01-44f4-b9ed-38b302bc7ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset CIFAR10\n",
      "Details about dataset: Total Datapoints: 50000, Dimensions: 32, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on Cifar10 data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
      "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.], device='cuda:0')\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 670, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 464, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 392, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIEvaluate(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 789, in run_psvi\n",
      "    test_acc, test_nll, iw_ent, ness, v_ent = self.evaluate()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 927, in evaluate\n",
      "    all_logits = self.model(all_data)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 620, in forward\n",
      "    out = self.layer2(out)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 550, in forward\n",
      "    out += self.shortcut(x)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 135, in forward\n",
      "    self._check_input_dim(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\", line 407, in _check_input_dim\n",
      "    raise ValueError(\"expected 4D input (got {}D input)\".format(input.dim()))\n",
      "ValueError: expected 4D input (got 5D input)\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"Cifar10\" \\\n",
    "--architecture \"resnet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 2 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved \\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace59900-a2d4-45ff-abc8-0e2963b7e4ef",
   "metadata": {},
   "source": [
    "### MNIST Random Evaluation from MFVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1723fd3-9c60-4574-8739-787052c81021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "Chosen indices: [40348, 13830, 52831, 53817, 38826, 51261, 16386, 48622, 2029, 50835, 48180, 50295, 31707, 26402, 39835, 39375, 48335, 9345, 45157, 6111, 38940, 31834, 49784, 4750, 20389, 56222, 13120, 23526, 30968, 6920]\n",
      "tensor([1, 0, 0, 8, 2, 4, 3, 7, 3, 4, 0, 2, 9, 6, 7, 4, 1, 8, 6, 8, 5, 9, 5, 1,\n",
      "        9, 2, 5, 7, 6, 3])\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.43%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 50%|█████████████████████▌                     | 10/20 [00:24<00:21,  2.19s/it]\n",
      "predictive accuracy: 67.70%\n",
      "100%|███████████████████████████████████████████| 20/20 [00:47<00:00,  2.38s/it]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 21 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --save_new_folder --log_pseudodata\\\n",
    "--mfvi_selection_method \"random\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd495cab-4293-4cd4-9a76-34bbc095fd19",
   "metadata": {},
   "source": [
    "### Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b45e80e-4ac0-428c-8c15-17a0f6b7fef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "center list: [13636, 20830, 37916, 44636, 8676, 44907, 47586, 26873, 5055, 12829, 17128, 48592, 48892, 26005, 11495, 44475, 18347, 5160, 9294, 30270]\n",
      "center list: [1763, 54327, 233, 4534, 50602, 51302, 65955, 9377, 74858, 58265, 51885, 15594, 16838, 63479, 17713, 58101, 26123, 73842, 72701, 29468]\n",
      "[13636, 20830, 37916, 44636, 8676, 44907, 47586, 26873, 5055, 12829, 17128, 48592, 48892, 26005, 11495, 44475, 18347, 5160, 9294, 30270, 1763, 54327, 233, 4534, 50602, 51302, 65955, 9377, 74858, 58265, 51885, 15594, 16838, 63479, 17713, 58101, 26123, 73842, 72701, 29468]\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]predictive accuracy: 63.90%\n",
      " 49%|████████████████████▌                     | 98/200 [00:01<00:01, 87.83it/s]predictive accuracy: 74.00%\n",
      "100%|█████████████████████████████████████████| 200/200 [00:03<00:00, 63.34it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_selection\" \\\n",
    "--log_every 100 --num_epochs 100 --mc_samples 256 --inner_it 20 --lr0net 1e-2 \\\n",
    "--coreset_sizes 40 --init_at \"subsample\" \\\n",
    "--pretrain_epochs 1 --load_from_saved\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--distance_fn \"cosine\" \\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43753db2-096a-41fe-87eb-bc08b5f349d8",
   "metadata": {},
   "source": [
    "### MNIST KMeans Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c653d64-893d-41fe-8f12-37306068e4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset FASHIONMNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on FashionMNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "Chosen indices: [45276, 57929, 21507, 37901, 10757, 15112, 8385, 30591, 14062, 39524, 44452, 32751, 55800, 43718, 50230, 41513, 28333, 33195, 55724, 26634, 50673, 10269, 22899, 27421, 30577, 3169, 51726, 23111, 12043, 36232]\n",
      "tensor([0, 9, 4, 3, 8, 8, 9, 3, 5, 7, 1, 5, 2, 4, 7, 6, 0, 9, 2, 1, 6, 6, 3, 2,\n",
      "        8, 1, 0, 7, 5, 4])\n",
      "  0%|                                                    | 0/21 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.79%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 48%|████████████████████▍                      | 10/21 [00:23<00:23,  2.13s/it]\n",
      "predictive accuracy: 60.21%\n",
      " 95%|████████████████████████████████████████▉  | 20/21 [00:46<00:02,  2.16s/it]\n",
      "predictive accuracy: 60.58%\n",
      "100%|███████████████████████████████████████████| 21/21 [00:50<00:00,  2.43s/it]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"FashionMNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 21 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0619557-ef08-46d4-b44c-18c2acbaab16",
   "metadata": {},
   "source": [
    "### Scored KMeans Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f30e9d-a16e-4245-926a-2258334a7057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 80 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:944: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "[ 619 2749  974 2836]\n",
      "[ 116 2098  376 2094]\n",
      "[ 746 1592  145 1894]\n",
      "[3239 1846 1107  257]\n",
      "[2489  743  128 2327]\n",
      "[ 111  953 2122   75]\n",
      "[2721 1605  945 2658]\n",
      "[1236 1105 1128 1619]\n",
      "[ 759  206  632 1994]\n",
      "[  10 3222 2776  580]\n",
      "[ 241 2905 3151 1343]\n",
      "[ 378 1814 1249 1495]\n",
      "[ 428  151  701 2115]\n",
      "[ 137 2583 2725 2715]\n",
      "[1273 1278 1614  306]\n",
      "[2296 2047  432 2110]\n",
      "[2463 2241  965 3755]\n",
      "[ 643 1384 1728  384]\n",
      "[ 152  799 2146 2603]\n",
      "[2264 2549 2429 2035]\n",
      "Chosen indices: [11794, 4327, 42845, 18424, 37137, 49242, 45821, 53439, 150, 44713, 14535, 3763, 14139, 2693, 15102, 30226, 15002, 42749, 54419, 11141, 43435, 53659, 43423, 51912, 2745, 26866, 38423, 51448, 47279, 55349, 4796, 20440, 15826, 3700, 9635, 1894, 57355, 9137, 42158, 39744, 45542, 45374, 52076, 20580, 49752, 9198, 21022, 25536, 24439, 23818, 8088, 51644, 35021, 43347, 47842, 3090, 28447, 58033, 3393, 5035, 15609, 54853, 54051, 44349, 51392, 40148, 49083, 18026, 22467, 2288, 2296, 54257, 43956, 40531, 27282, 12663, 22588, 19639, 47355, 57073]\n",
      "tensor([0, 5, 9, 0, 5, 7, 4, 4, 4, 5, 3, 1, 2, 2, 8, 3, 1, 8, 4, 5, 3, 8, 0, 6,\n",
      "        0, 3, 8, 2, 1, 5, 4, 2, 6, 6, 6, 2, 8, 4, 2, 3, 6, 7, 6, 8, 9, 7, 4, 3,\n",
      "        5, 1, 0, 9, 8, 0, 2, 9, 7, 1, 1, 7, 9, 0, 5, 3, 5, 1, 6, 4, 7, 2, 6, 9,\n",
      "        7, 9, 3, 8, 7, 1, 9, 0])\n",
      "  0%|                                                   | 0/101 [00:00<?, ?it/s]^C\n",
      "  0%|                                                   | 0/101 [00:30<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 676, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 470, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 398, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIEvaluate(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 884, in run_psvi\n",
      "    self._forgetting_calculator()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1280, in _forgetting_calculator\n",
      "    train_logits = self.model(xbatch).squeeze(-1).mean(0)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 254, in forward\n",
      "    x = super().forward(x.flatten(0, 1))\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/pooling.py\", line 162, in forward\n",
      "    return F.max_pool2d(input, self.kernel_size, self.stride,\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/_jit_internal.py\", line 423, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/functional.py\", line 782, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 101 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 80 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"scored_kmeans_entropy\" --num_trials 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e3fc3-4291-4b73-b727-f1a724cf72cd",
   "metadata": {},
   "source": [
    "### Other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2663eeca-686c-49c2-b163-a3a6592e803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 80 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "Chosen indices: [999, 5942, 42114, 49003, 10995, 47283, 55395, 8300, 52141, 9661, 191, 14280, 943, 58539, 31255, 41192, 25783, 35301, 1904, 50025, 36638, 30198, 45526, 50473, 54929, 52757, 50536, 13150, 18712, 53852, 15562, 19924, 2220, 27204, 57909, 55310, 50520, 23770, 56714, 33510, 47951, 4334, 34919, 46976, 27848, 14936, 40191, 16320, 19264, 41785, 9294, 19252, 46115, 37921, 28260, 49919, 16997, 6600, 17188, 46383, 19886, 27730, 59354, 24, 51536, 55258, 22650, 20464, 22976, 22743, 27455, 27210, 54778, 5113, 25504, 53682, 32309, 25568, 33437, 17583]\n",
      "tensor([6, 3, 3, 9, 5, 8, 8, 8, 6, 8, 5, 7, 0, 9, 6, 4, 0, 2, 0, 3, 5, 4, 5, 9,\n",
      "        6, 2, 7, 7, 0, 7, 9, 0, 4, 6, 3, 1, 7, 2, 1, 3, 5, 7, 0, 4, 9, 1, 6, 2,\n",
      "        3, 6, 3, 4, 2, 0, 9, 1, 0, 7, 2, 6, 2, 9, 1, 1, 3, 4, 5, 4, 8, 7, 1, 8,\n",
      "        4, 2, 1, 9, 8, 8, 5, 5])\n",
      "  0%|                                                   | 0/101 [00:00<?, ?it/s]^C\n",
      "  0%|                                                   | 0/101 [00:24<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 676, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 470, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 398, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIEvaluate(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 884, in run_psvi\n",
      "    self._forgetting_calculator()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1280, in _forgetting_calculator\n",
      "    train_logits = self.model(xbatch).squeeze(-1).mean(0)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 254, in forward\n",
      "    x = super().forward(x.flatten(0, 1))\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/pooling.py\", line 162, in forward\n",
      "    return F.max_pool2d(input, self.kernel_size, self.stride,\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/_jit_internal.py\", line 423, in fn\n",
      "    return if_false(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/functional.py\", line 782, in _max_pool2d\n",
      "    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 101 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 80 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"least_confidence\" --num_trials 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db128282-d32b-4095-b68a-a4dd46965c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb45e34-7a05-4d9f-be28-e65a62293aa1",
   "metadata": {},
   "source": [
    "### Rest of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ae4691d-a9ee-48b3-b188-ff4e617dceec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SUBSET on webspam data over 3 independent trials.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_subset\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 69.62%\n",
      "  8%|███▍                                       | 8/100 [00:01<00:11,  8.30it/s]predictive accuracy: 74.23%\n",
      " 17%|███████▏                                  | 17/100 [00:02<00:09,  9.11it/s]predictive accuracy: 76.61%\n",
      " 28%|███████████▊                              | 28/100 [00:04<00:07,  9.76it/s]predictive accuracy: 78.14%\n",
      " 40%|████████████████▊                         | 40/100 [00:05<00:05, 10.36it/s]predictive accuracy: 80.42%\n",
      " 48%|████████████████████▏                     | 48/100 [00:07<00:06,  8.16it/s]predictive accuracy: 82.08%\n",
      " 59%|████████████████████████▊                 | 59/100 [00:08<00:04,  9.03it/s]predictive accuracy: 82.49%\n",
      " 68%|████████████████████████████▌             | 68/100 [00:10<00:03,  8.25it/s]predictive accuracy: 82.48%\n",
      " 76%|███████████████████████████████▉          | 76/100 [00:11<00:03,  7.55it/s]predictive accuracy: 82.14%\n",
      " 88%|████████████████████████████████████▉     | 88/100 [00:12<00:01, 10.14it/s]predictive accuracy: 81.94%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:14<00:00,  6.97it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 80 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 68.45%\n",
      "  9%|███▊                                       | 9/100 [00:00<00:06, 13.38it/s]predictive accuracy: 76.38%\n",
      " 20%|████████▍                                 | 20/100 [00:02<00:06, 11.50it/s]predictive accuracy: 77.20%\n",
      " 28%|███████████▊                              | 28/100 [00:03<00:07,  9.50it/s]predictive accuracy: 78.25%\n",
      " 39%|████████████████▍                         | 39/100 [00:04<00:05, 10.35it/s]predictive accuracy: 80.26%\n",
      " 50%|█████████████████████                     | 50/100 [00:06<00:04, 10.76it/s]predictive accuracy: 81.96%\n",
      " 58%|████████████████████████▎                 | 58/100 [00:07<00:04,  9.88it/s]predictive accuracy: 83.75%\n",
      " 69%|████████████████████████████▉             | 69/100 [00:09<00:02, 10.36it/s]predictive accuracy: 84.54%\n",
      " 79%|█████████████████████████████████▏        | 79/100 [00:10<00:01, 11.65it/s]predictive accuracy: 84.90%\n",
      " 88%|████████████████████████████████████▉     | 88/100 [00:11<00:01,  9.70it/s]predictive accuracy: 85.29%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  7.82it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #1\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 61.90%\n",
      "  9%|███▊                                       | 9/100 [00:01<00:09,  9.91it/s]predictive accuracy: 70.60%\n",
      " 18%|███████▌                                  | 18/100 [00:02<00:10,  8.19it/s]predictive accuracy: 71.96%\n",
      " 30%|████████████▌                             | 30/100 [00:04<00:06, 10.36it/s]predictive accuracy: 72.76%\n",
      " 38%|███████████████▉                          | 38/100 [00:05<00:06,  9.70it/s]predictive accuracy: 73.94%\n",
      " 49%|████████████████████▌                     | 49/100 [00:06<00:04, 10.98it/s]predictive accuracy: 74.88%\n",
      " 59%|████████████████████████▊                 | 59/100 [00:07<00:03, 11.18it/s]predictive accuracy: 75.69%\n",
      " 68%|████████████████████████████▌             | 68/100 [00:09<00:03,  9.76it/s]predictive accuracy: 76.31%\n",
      " 76%|███████████████████████████████▉          | 76/100 [00:10<00:02,  8.02it/s]predictive accuracy: 76.96%\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [00:11<00:01, 10.53it/s]predictive accuracy: 77.06%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:13<00:00,  7.50it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 80 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 61.84%\n",
      " 10%|████▏                                     | 10/100 [00:01<00:08, 10.53it/s]predictive accuracy: 71.87%\n",
      " 17%|███████▏                                  | 17/100 [00:02<00:10,  8.13it/s]predictive accuracy: 74.22%\n",
      " 29%|████████████▏                             | 29/100 [00:04<00:07, 10.11it/s]predictive accuracy: 75.72%\n",
      " 39%|████████████████▍                         | 39/100 [00:05<00:05, 10.26it/s]predictive accuracy: 77.16%\n",
      " 48%|████████████████████▏                     | 48/100 [00:06<00:05, 10.38it/s]predictive accuracy: 78.42%\n",
      " 60%|█████████████████████████▏                | 60/100 [00:08<00:03, 10.67it/s]predictive accuracy: 79.06%\n",
      " 69%|████████████████████████████▉             | 69/100 [00:10<00:03,  8.49it/s]predictive accuracy: 79.88%\n",
      " 79%|█████████████████████████████████▏        | 79/100 [00:11<00:02,  9.01it/s]predictive accuracy: 80.41%\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [00:12<00:00, 11.53it/s]predictive accuracy: 80.95%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:14<00:00,  7.11it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #2\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 41.95%\n",
      "  9%|███▊                                       | 9/100 [00:01<00:08, 10.59it/s]predictive accuracy: 77.06%\n",
      " 18%|███████▌                                  | 18/100 [00:02<00:08,  9.58it/s]predictive accuracy: 79.82%\n",
      " 28%|███████████▊                              | 28/100 [00:03<00:06, 11.09it/s]predictive accuracy: 82.19%\n",
      " 39%|████████████████▍                         | 39/100 [00:04<00:04, 12.65it/s]predictive accuracy: 82.49%\n",
      " 47%|███████████████████▋                      | 47/100 [00:05<00:04, 10.83it/s]predictive accuracy: 82.49%\n",
      " 57%|███████████████████████▉                  | 57/100 [00:07<00:04, 10.12it/s]predictive accuracy: 82.93%\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:08<00:02, 12.87it/s]predictive accuracy: 83.14%\n",
      " 78%|████████████████████████████████▊         | 78/100 [00:09<00:02,  9.99it/s]predictive accuracy: 83.41%\n",
      " 88%|████████████████████████████████████▉     | 88/100 [00:10<00:01,  9.36it/s]predictive accuracy: 83.88%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  8.19it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 80 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 72.68%\n",
      "  9%|███▊                                       | 9/100 [00:01<00:09,  9.50it/s]predictive accuracy: 78.05%\n",
      " 20%|████████▍                                 | 20/100 [00:02<00:07, 11.22it/s]predictive accuracy: 79.96%\n",
      " 29%|████████████▏                             | 29/100 [00:04<00:07,  9.60it/s]predictive accuracy: 80.92%\n",
      " 40%|████████████████▊                         | 40/100 [00:05<00:05, 10.60it/s]predictive accuracy: 81.86%\n",
      " 50%|█████████████████████                     | 50/100 [00:07<00:05,  9.24it/s]predictive accuracy: 82.12%\n",
      " 60%|█████████████████████████▏                | 60/100 [00:09<00:04,  9.80it/s]predictive accuracy: 82.54%\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:10<00:03,  9.29it/s]predictive accuracy: 82.74%\n",
      " 80%|█████████████████████████████████▌        | 80/100 [00:12<00:02,  9.98it/s]predictive accuracy: 83.00%\n",
      " 89%|█████████████████████████████████████▍    | 89/100 [00:13<00:01,  8.53it/s]predictive accuracy: 83.44%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:15<00:00,  6.47it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_subset\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 10 --num_epochs 50 --mc_samples 256 --inner_it 1000 --lr0net 1e-2\\\n",
    "--save_new_folder\\\n",
    "--coreset_sizes 40 80 --init_at \"subsample\" --num_trials 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c842dd6f-8495-4ed5-860c-2fb17235c751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset CIFAR10\n",
      "Details about dataset: Total Datapoints: 50000, Dimensions: 32, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_FIXED_U on Cifar10 data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 664, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 458, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 383, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIFixedU(*args, **kwargs).run_psvi(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 762, in run_psvi\n",
      "    test_acc, test_nll, iw_ent, ness, v_ent = self.evaluate()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 897, in evaluate\n",
      "    all_logits = self.model(all_data)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 225, in forward\n",
      "    a = F.conv2d(\n",
      "RuntimeError: Given groups=10, weight of size [60, 1, 5, 5], expected input[168, 30, 32, 32] to have 10 channels, but got 30 channels instead\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"Cifar10\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 10 --num_epochs 50 --mc_samples 10 --inner_it 100 --lr0net 1e-2\\\n",
    "--coreset_sizes 40 --init_at \"subsample\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c42fda-1d45-4784-b3ac-0c4a6a556e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via SPARSEVI on webspam data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running sparsevi\n",
      "\n",
      "Trial #0\n",
      "Unconstrained data access\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]predictive accuracy: 39.31%\n",
      " 20%|████████                                | 10/50 [23:47<1:36:00, 144.01s/it]predictive accuracy: 66.55%\n",
      " 40%|████████████████                        | 20/50 [48:11<1:12:55, 145.86s/it]predictive accuracy: 77.86%\n",
      " 60%|████████████████████████                | 30/50 [1:12:27<48:32, 145.62s/it]predictive accuracy: 77.88%\n",
      " 80%|████████████████████████████████        | 40/50 [1:36:46<24:19, 145.99s/it]predictive accuracy: 77.42%\n",
      "100%|████████████████████████████████████████| 50/50 [2:01:07<00:00, 145.36s/it]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"sparsevi\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 10 --num_epochs 50 --mc_samples 256 --inner_it 200 \\\n",
    "--outer_it 400 --lr0net 1e-2 --save_new_folder\\\n",
    "--coreset_sizes 40 80 --init_at \"random\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc38d93a-3012-49a2-a1ca-49dfef6f7e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset HALFMOON\n",
      "Details about dataset: Total Datapoints: 800, Dimensions: 2, num classes: 2\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via MFVI_SUBSET on halfmoon data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_subset\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                   | 0/202 [00:00<?, ?it/s]/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "predictive accuracy: 83.00%\n",
      " 24%|██████████▏                               | 49/202 [00:12<00:11, 12.93it/s]predictive accuracy: 84.50%\n",
      " 49%|████████████████████▌                     | 99/202 [00:16<00:05, 17.91it/s]predictive accuracy: 84.00%\n",
      " 74%|██████████████████████████████▏          | 149/202 [00:27<00:03, 13.38it/s]predictive accuracy: 84.00%\n",
      " 99%|████████████████████████████████████████▍| 199/202 [00:31<00:00, 10.36it/s]predictive accuracy: 84.00%\n",
      "100%|█████████████████████████████████████████| 202/202 [00:41<00:00,  4.90it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"halfmoon\" \\\n",
    "--architecture \"fn\" --n_hidden 100 --methods \"mfvi_subset\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 50 --num_epochs 101 --mc_samples 64 --inner_it 500 --lr0net 1e-2 \\\n",
    "--init_sd 1e-3 --data_minibatch 256 --log_pseudodata\\\n",
    "--save_new_folder \\\n",
    "--coreset_sizes 10 --init_at \"subsample\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2839fb7a-f6fe-4597-8ba2-2621a6a6c1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset HALFMOON\n",
      "Details about dataset: Total Datapoints: 800, Dimensions: 2, num classes: 2\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via MFVI_SELECTION on halfmoon data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:793: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/202 [00:00<?, ?it/s]predictive accuracy: 29.00%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      " 24%|██████████▏                               | 49/202 [00:12<00:11, 12.98it/s]predictive accuracy: 25.00%\n",
      " 49%|████████████████████▌                     | 99/202 [00:15<00:07, 14.35it/s]predictive accuracy: 24.50%\n",
      " 74%|██████████████████████████████▏          | 149/202 [00:22<00:01, 27.36it/s]predictive accuracy: 24.50%\n",
      " 99%|████████████████████████████████████████▍| 199/202 [00:24<00:00, 28.70it/s]predictive accuracy: 24.50%\n",
      "100%|█████████████████████████████████████████| 202/202 [00:29<00:00,  6.91it/s]\n",
      "Storing pseudodata\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"halfmoon\" \\\n",
    "--architecture \"fn\" --n_hidden 100 --methods \"mfvi_selection\" \\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 50 --num_epochs 101 --mc_samples 64 --inner_it 500 --lr0net 1e-2 \\\n",
    "--init_sd 1e-3 --data_minibatch 256 --log_pseudodata \\\n",
    "--pretrain_epochs 5 \\\n",
    "--save_new_folder --load_from_saved \\\n",
    "--mfvi_selection_method \"el2n\" \\\n",
    "--coreset_sizes 10 --init_at \"subsample\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a4ed59-4968-44ed-a3c6-f42a12f0c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14286439-d84f-4a91-88bb-72e2795cb424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset HALFMOON\n",
      "Details about dataset: Total Datapoints: 800, Dimensions: 2, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI on halfmoon data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi\n",
      "\n",
      "Trial #0\n",
      "Unconstrained data access\n",
      "  0%|                                                   | 0/202 [00:00<?, ?it/s]/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "predictive accuracy: 82.00%\n",
      " 21%|████████▉                                 | 43/202 [00:00<00:02, 76.30it/s]predictive accuracy: 83.00%\n",
      " 47%|███████████████████▊                      | 95/202 [00:01<00:01, 96.07it/s]predictive accuracy: 83.00%\n",
      " 74%|██████████████████████████████▏          | 149/202 [00:01<00:00, 89.54it/s]predictive accuracy: 84.00%\n",
      " 95%|██████████████████████████████████████▉  | 192/202 [00:02<00:00, 99.01it/s]predictive accuracy: 84.50%\n",
      "predictive accuracy: 84.50%\n",
      "100%|█████████████████████████████████████████| 202/202 [00:02<00:00, 74.42it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"halfmoon\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 50 --num_epochs 101 --mc_samples 64 --inner_it 500 --lr0net 1e-2 \\\n",
    "--init_sd 1e-3 --data_minibatch 256\\\n",
    "--log_pseudodata\\\n",
    "--coreset_sizes 40 --init_at \"subsample\" --num_trials 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1379fef5-739a-46a9-ac3d-09f6e5c2d0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.43%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [00:23<03:15,  2.17s/it]\n",
      "predictive accuracy: 67.24%\n",
      " 20%|████████▍                                 | 20/100 [00:47<02:52,  2.16s/it]\n",
      "predictive accuracy: 69.20%\n",
      " 30%|████████████▌                             | 30/100 [01:10<02:31,  2.16s/it]\n",
      "predictive accuracy: 69.40%\n",
      " 40%|████████████████▊                         | 40/100 [01:34<02:09,  2.15s/it]\n",
      "predictive accuracy: 69.49%\n",
      " 50%|█████████████████████                     | 50/100 [01:57<01:47,  2.16s/it]\n",
      "predictive accuracy: 69.03%\n",
      " 60%|█████████████████████████▏                | 60/100 [02:20<01:25,  2.13s/it]\n",
      "predictive accuracy: 69.31%\n",
      " 70%|█████████████████████████████▍            | 70/100 [02:44<01:05,  2.18s/it]\n",
      "predictive accuracy: 68.99%\n",
      " 80%|█████████████████████████████████▌        | 80/100 [03:07<00:42,  2.13s/it]\n",
      "predictive accuracy: 68.18%\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [03:33<00:22,  2.26s/it]\n",
      "predictive accuracy: 68.64%\n",
      "100%|█████████████████████████████████████████| 100/100 [03:56<00:00,  2.37s/it]\n",
      "Trial completed!\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 641, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 501, in experiment_driver\n",
      "    return write_to_files(results, method_args[\"fnm\"], method_args)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 629, in write_to_files\n",
      "    json.dump(results, fp)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 325, in _iterencode_list\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ndarray is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --num_trials 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4fd8a1-26f6-4aaf-82c3-8833d57cd15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via PSVI_FIXED_U on webspam data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "  0%|                                                    | 0/50 [00:00<?, ?it/s]\n",
      "predictive accuracy: 39.18%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "  8%|███▌                                        | 4/50 [01:45<19:44, 25.75s/it]/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in SoftplusBackwardBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 589, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 407, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 333, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIFixedU(*args, **kwargs).run_psvi(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 735, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1314, in nested_step\n",
      "    diffopt.step(mfvi_loss)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 224, in step\n",
      "    all_grads = _torch.autograd.grad(\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 276, in grad\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: \n",
      "\n",
      "Previous calculation was induced by SoftplusBackward0. Traceback of forward call that induced the previous calculation:\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 589, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 407, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 333, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIFixedU(*args, **kwargs).run_psvi(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 735, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1310, in nested_step\n",
      "    mfvi_loss = self.inner_elbo(model=fmodel)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 306, in inner_elbo\n",
      "    logits = model(self.u) if not hyperopt else model(self.u, params=params)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/patch.py\", line 460, in _patched_forward\n",
      "    output = self.boxed_forward(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/patch.py\", line 388, in patched_forward\n",
      "    return true_forward(self, *args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/container.py\", line 139, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/patch.py\", line 388, in patched_forward\n",
      "    return true_forward(self, *args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 177, in forward\n",
      "    self._cached_weight, self._cached_bias = self.rsample()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 155, in rsample\n",
      "    weight = self.weight_dist.rsample(self.weight_batch_shape)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 119, in weight_dist\n",
      "    dist.Normal(self.weight, self.weight_sd), self.weight.ndim\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/models/neural_net.py\", line 130, in weight_sd\n",
      "    return F.softplus(self._weight_sd)\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  8%|███▌                                        | 4/50 [02:05<24:06, 31.44s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 589, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 407, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 333, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIFixedU(*args, **kwargs).run_psvi(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 735, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1319, in nested_step\n",
      "    psvi_loss.backward()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: Function 'SoftplusBackwardBackward0' returned nan values in its 1th output.\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"psvi_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 10 --num_epochs 50 --mc_samples 256 --inner_it 500 --lr0net 1e-2\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --num_trials 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0156ba23-b2aa-4edf-91c2-37af274cb7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SUBSET on webspam data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_subset\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]predictive accuracy: 39.09%\n",
      " 10%|████▏                                     | 10/100 [00:01<00:07, 12.13it/s]predictive accuracy: 70.34%\n",
      " 18%|███████▌                                  | 18/100 [00:02<00:10,  8.11it/s]predictive accuracy: 68.44%\n",
      " 27%|███████████▎                              | 27/100 [00:04<00:09,  7.87it/s]predictive accuracy: 69.40%\n",
      " 40%|████████████████▊                         | 40/100 [00:06<00:06,  9.96it/s]predictive accuracy: 70.92%\n",
      " 50%|█████████████████████                     | 50/100 [00:07<00:05,  8.81it/s]predictive accuracy: 71.41%\n",
      " 57%|███████████████████████▉                  | 57/100 [00:08<00:05,  7.58it/s]predictive accuracy: 71.38%\n",
      " 70%|█████████████████████████████▍            | 70/100 [00:10<00:02, 10.36it/s]predictive accuracy: 71.88%\n",
      " 79%|█████████████████████████████████▏        | 79/100 [00:11<00:02,  8.88it/s]predictive accuracy: 72.50%\n",
      " 88%|████████████████████████████████████▉     | 88/100 [00:13<00:01,  8.42it/s]predictive accuracy: 73.10%\n",
      "100%|█████████████████████████████████████████| 100/100 [00:15<00:00,  6.59it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_subset\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 10 --num_epochs 50 --mc_samples 256 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 40 --init_at \"subsample\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "198447f7-82e6-4633-96fa-01518887362f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:767: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]predictive accuracy: 39.67%\n",
      " 18%|███████▌                                  | 36/200 [00:00<00:02, 58.75it/s]predictive accuracy: 73.61%\n",
      " 40%|████████████████▊                         | 80/200 [00:01<00:01, 60.89it/s]predictive accuracy: 75.10%\n",
      " 57%|███████████████████████▌                 | 115/200 [00:02<00:01, 55.67it/s]predictive accuracy: 76.61%\n",
      " 80%|████████████████████████████████▌        | 159/200 [00:03<00:00, 60.43it/s]predictive accuracy: 77.45%\n",
      "100%|█████████████████████████████████████████| 200/200 [00:04<00:00, 42.64it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_selection\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 40 --num_epochs 100 --mc_samples 256 --inner_it 20 --lr0net 1e-2\\\n",
    "--coreset_sizes 40 --init_at \"subsample\"\\\n",
    "--pretrain_epochs 2 --load_from_saved\\\n",
    "--mfvi_selection_method \"scored_random_entropy\" --num_trials 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a13a37a-128f-403d-b32a-f6c08db80abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 603, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 420, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/baselines.py\", line 1764, in run_selection_with_mfvi\n",
      "    mfvi_select.select_data()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/baselines.py\", line 1605, in select_data\n",
      "    select_method.pretrain(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 494, in pretrain\n",
      "    self.pretrained_vi.run()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 341, in run\n",
      "    self.train_an_epoch()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 242, in train_an_epoch\n",
      "    * self.distr_fn(logits=self.net(xbatch).squeeze(-1)).log_prob(ybatch).sum()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/distributions/categorical.py\", line 121, in log_prob\n",
      "    self._validate_sample(value)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/distributions/distribution.py\", line 281, in _validate_sample\n",
      "    raise ValueError('Value is not broadcastable with batch_shape+event_shape: {} vs {}.'.\n",
      "ValueError: Value is not broadcastable with batch_shape+event_shape: torch.Size([128]) vs torch.Size([128, 256, 28]).\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_selection\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 40 --num_epochs 100 --mc_samples 256 --inner_it 20 --lr0net 1e-2\\\n",
    "--coreset_sizes 40 --init_at \"subsample\"\\\n",
    "--mfvi_selection_method \"scored_kmeans_el2n\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43047c73-f204-4bc4-b39c-3083b21d4718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via MFVI_SELECTION on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 664, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 458, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/baselines.py\", line 1951, in run_selection_with_mfvi\n",
      "    mfvi_select.select_data()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/baselines.py\", line 1617, in select_data\n",
      "    select_method.select_data()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 1230, in select_data\n",
      "    self.chosen_dataset = select_method.get_weighted_subset()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 547, in get_weighted_subset\n",
      "    self.core_idc = self.select()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 1344, in select\n",
      "    gradients = self._get_embeddings()\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py\", line 1302, in _get_embeddings\n",
      "    with torch.no_grad():\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"mfvi_selection\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--log_every 40 --num_epochs 100 --mc_samples 256 --inner_it 20 --lr0net 1e-2\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" \\\n",
    "--load_from_saved \\\n",
    "--mfvi_selection_method \"submodular\" --pretrain_epochs 5 --num_trials 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8142273-cb99-4990-9fe4-68f0e098d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
      "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.], device='cuda:0')\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.43%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [00:23<03:14,  2.16s/it]\n",
      "predictive accuracy: 67.15%\n",
      " 20%|████████▍                                 | 20/100 [00:46<02:50,  2.13s/it]\n",
      "predictive accuracy: 67.97%\n",
      " 30%|████████████▌                             | 30/100 [01:10<02:29,  2.14s/it]\n",
      "predictive accuracy: 68.47%\n",
      " 40%|████████████████▊                         | 40/100 [01:33<02:08,  2.14s/it]\n",
      "predictive accuracy: 69.61%\n",
      " 50%|█████████████████████                     | 50/100 [01:56<01:46,  2.13s/it]\n",
      "predictive accuracy: 68.43%\n",
      " 60%|█████████████████████████▏                | 60/100 [02:19<01:25,  2.13s/it]\n",
      "predictive accuracy: 68.73%\n",
      " 70%|█████████████████████████████▍            | 70/100 [02:42<01:04,  2.16s/it]\n",
      "predictive accuracy: 68.93%\n",
      " 76%|███████████████████████████████▉          | 76/100 [02:57<00:54,  2.25s/it]^C\n",
      " 76%|███████████████████████████████▉          | 76/100 [02:58<00:56,  2.35s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 664, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 458, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 386, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIAFixedU(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 810, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1611, in nested_step\n",
      "    diffopt.step(mfvi_loss)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 244, in step\n",
      "    self._update(grouped_grads)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 341, in _update\n",
      "    state[\"exp_avg_sq\"] = exp_avg_sq = (exp_avg_sq * beta2) + (\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/traceback.py\", line 197, in format_stack\n",
      "    return format_list(extract_stack(f, limit=limit))\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/traceback.py\", line 211, in extract_stack\n",
      "    stack = StackSummary.extract(walk_stack(f), limit=limit)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/traceback.py\", line 362, in extract\n",
      "    linecache.checkcache(filename)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/linecache.py\", line 58, in checkcache\n",
      "    elif filename in cache:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef69f72-fcc9-44c5-a73a-8f3f57ccf2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "Chosen indices: [4738, 29292, 59232, 22770, 49088, 30967, 6166, 47643, 9743, 55829, 26531, 6853, 26157, 14966, 12304, 25037, 42488, 32930, 45943, 35396, 46590, 52265, 41820, 56752, 6938, 29375, 39326, 40387, 19973, 21973]\n",
      "tensor([0, 9, 4, 3, 8, 8, 9, 3, 5, 7, 1, 5, 2, 4, 7, 6, 0, 9, 2, 1, 6, 6, 3, 2,\n",
      "        8, 1, 0, 7, 5, 4])\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.33%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [00:23<03:16,  2.19s/it]\n",
      "predictive accuracy: 73.18%\n",
      " 20%|████████▍                                 | 20/100 [00:47<02:54,  2.18s/it]\n",
      "predictive accuracy: 73.66%\n",
      " 30%|████████████▌                             | 30/100 [01:10<02:30,  2.15s/it]\n",
      "predictive accuracy: 72.83%\n",
      " 40%|████████████████▊                         | 40/100 [01:34<02:11,  2.19s/it]\n",
      "predictive accuracy: 72.24%\n",
      " 50%|█████████████████████                     | 50/100 [01:58<01:50,  2.21s/it]\n",
      "predictive accuracy: 71.91%\n",
      " 60%|█████████████████████████▏                | 60/100 [02:21<01:26,  2.17s/it]\n",
      "predictive accuracy: 71.46%\n",
      " 70%|█████████████████████████████▍            | 70/100 [02:45<01:05,  2.17s/it]\n",
      "predictive accuracy: 71.58%\n",
      " 80%|█████████████████████████████████▌        | 80/100 [03:08<00:43,  2.17s/it]\n",
      "predictive accuracy: 72.54%\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [03:32<00:21,  2.18s/it]\n",
      "predictive accuracy: 71.41%\n",
      "100%|█████████████████████████████████████████| 100/100 [03:56<00:00,  2.36s/it]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"custom\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved --log_pseudodata --save_new_folder\\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96699c7e-6202-4eea-9139-9db95ee60d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset MNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_ALPHA_FIXED_U on MNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_alpha_fixed_u\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.43%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [00:24<03:17,  2.19s/it]\n",
      "predictive accuracy: 69.60%\n",
      " 20%|████████▍                                 | 20/100 [00:47<02:56,  2.21s/it]\n",
      "predictive accuracy: 70.94%\n",
      " 30%|████████████▌                             | 30/100 [01:11<02:32,  2.18s/it]\n",
      "predictive accuracy: 70.00%\n",
      " 40%|████████████████▊                         | 40/100 [01:35<02:10,  2.18s/it]\n",
      "predictive accuracy: 71.04%\n",
      " 50%|█████████████████████                     | 50/100 [01:59<01:49,  2.19s/it]\n",
      "predictive accuracy: 70.02%\n",
      " 60%|█████████████████████████▏                | 60/100 [02:22<01:26,  2.17s/it]\n",
      "predictive accuracy: 70.48%\n",
      " 70%|█████████████████████████████▍            | 70/100 [02:46<01:06,  2.21s/it]\n",
      "predictive accuracy: 70.06%\n",
      " 80%|█████████████████████████████████▌        | 80/100 [03:09<00:43,  2.15s/it]\n",
      "predictive accuracy: 69.95%\n",
      " 90%|█████████████████████████████████████▊    | 90/100 [03:33<00:21,  2.16s/it]\n",
      "predictive accuracy: 69.76%\n",
      "100%|█████████████████████████████████████████| 100/100 [03:57<00:00,  2.37s/it]\n",
      "Trial completed!\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 641, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 501, in experiment_driver\n",
      "    return write_to_files(results, method_args[\"fnm\"], method_args)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 629, in write_to_files\n",
      "    json.dump(results, fp)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/__init__.py\", line 179, in dump\n",
      "    for chunk in iterable:\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 431, in _iterencode\n",
      "    yield from _iterencode_dict(o, _current_indent_level)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 405, in _iterencode_dict\n",
      "    yield from chunks\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 325, in _iterencode_list\n",
      "    yield from chunks\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 438, in _iterencode\n",
      "    o = _default(o)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/json/encoder.py\", line 179, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type ndarray is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_alpha_fixed_u\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"custom\" \\\n",
    "--mfvi_selection_method \"scored_kmeans_least_confidence\" --num_trials 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4979c915-d685-4766-84ed-33f6b6f7cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset FASHIONMNIST\n",
      "Details about dataset: Total Datapoints: 60000, Dimensions: 28, num classes: 10\n",
      "\n",
      "Bayesian neural network experiment.\n",
      "Inference via PSVI_EVALUATE on FashionMNIST data over 1 trial.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running psvi_evaluate\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 30 datapoints\n",
      "SETTING UP THE MODEL \n",
      "\n",
      "\n",
      "tensor([0., 0., 0., 1., 1., 1., 2., 2., 2., 3., 3., 3., 4., 4., 4., 5., 5., 5.,\n",
      "        6., 6., 6., 7., 7., 7., 8., 8., 8., 9., 9., 9.])\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]\n",
      "predictive accuracy: 9.52%\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      " 10%|████▏                                     | 10/100 [02:23<18:30, 12.34s/it]\n",
      "predictive accuracy: 51.28%\n",
      " 20%|████████▍                                 | 20/100 [04:25<15:32, 11.66s/it]\n",
      "predictive accuracy: 52.76%\n",
      " 25%|██████████▌                               | 25/100 [05:26<13:13, 10.58s/it]^C\n",
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in AddBackward0. Traceback of forward call that caused the error:\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 670, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 464, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 392, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIEvaluate(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 810, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1657, in nested_step\n",
      "    diffopt.step(mfvi_loss)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 244, in step\n",
      "    self._update(grouped_grads)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 341, in _update\n",
      "    state[\"exp_avg_sq\"] = exp_avg_sq = (exp_avg_sq * beta2) + (\n",
      " (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:104.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      " 25%|██████████▌                               | 25/100 [05:35<16:47, 13.43s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 670, in <module>\n",
      "    (experiment_driver(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 464, in experiment_driver\n",
      "    results[dnm][nm_alg][ps][t] = inf_alg(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi_experiments.py\", line 392, in <lambda>\n",
      "    lambda *args, **kwargs: PSVIEvaluate(*args, **kwargs).run_psvi(\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 810, in run_psvi\n",
      "    psvi_step(xbatch, ybatch)\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/psvi_classes.py\", line 1662, in nested_step\n",
      "    psvi_loss.backward()\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/home/studio-lab-user/Blackbox-Coresets-VI/psvi/robust_higher/optim.py\", line 41, in closure\n",
      "    def closure(grad: _torch.Tensor) -> _torch.Tensor:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 psvi_experiments.py --datasets \"FashionMNIST\" \\\n",
    "--architecture \"lenet\" --n_hidden 100 --methods \"psvi_evaluate\"\\\n",
    "--data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "--results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "--learn_z --data_minibatch 256 --lr0u 1e-2 --lr0v 1e-2 --lr0z 1e-2 --lr0alpha 1e-3\\\n",
    "--log_every 10 --num_epochs 100 --mc_samples 10 --inner_it 20 --lr0net 1e-3\\\n",
    "--coreset_sizes 30 --init_at \"subsample\" --distance_fn \"cosine\"\\\n",
    "--pretrain_epochs 5 --load_from_saved \\\n",
    "--mfvi_selection_method \"kmeans\" --num_trials 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab727511-c710-4426-b676-49f3ccc6384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.81494140625"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb57283-91d7-41c7-83ff-124976e28e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run all experiments for webspam\n",
    "#selection_method = [\n",
    "#    \"kmeans\", \"random\", \"el2n\", \"least_confidence\", \"entropy\", \"forgetting\",\n",
    "#    \"scored_kmeans_el2n\", \"scored_kmeans_forgetting\", \n",
    "#    \"scored_kmeans_entropy\", \"scored_kmeans_least_confidence\"\n",
    "#]\n",
    "\n",
    "selection_method = [\n",
    "    \"scored_kmeans_entropy\", \"scored_kmeans_least_confidence\"\n",
    "]\n",
    "\n",
    "lr_list = [1e-2, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430d7be8-cad8-440c-b3c3-f3627f994275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 3 independent trials.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:24<00:27, 27.61s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:49<00:00, 27.31s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 67.09%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:06, 47.08it/s]predictive accuracy: 65.29%\n",
      " 49%|███████████████████▉                     | 195/400 [00:05<00:03, 57.91it/s]predictive accuracy: 65.00%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:08<00:01, 63.48it/s]predictive accuracy: 64.92%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 34.97it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:31<00:30, 30.01s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [02:02<00:00, 30.69s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 69.14%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:06, 45.90it/s]predictive accuracy: 77.02%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:04, 45.80it/s]predictive accuracy: 78.55%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:09<00:02, 45.42it/s]predictive accuracy: 78.58%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 33.55it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:17<00:25, 25.48s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:47<00:00, 26.90s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 71.60%\n",
      " 25%|██████████▍                               | 99/400 [00:03<00:08, 37.16it/s]predictive accuracy: 77.12%\n",
      " 49%|████████████████████▏                    | 197/400 [00:07<00:05, 38.38it/s]predictive accuracy: 75.90%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:11<00:02, 36.93it/s]predictive accuracy: 75.58%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 26.41it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #1\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:30<00:30, 30.01s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [02:00<00:00, 30.17s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.23%\n",
      " 25%|██████████▏                              | 99/400 [00:01<00:02, 101.01it/s]predictive accuracy: 74.54%\n",
      " 50%|████████████████████▎                    | 198/400 [00:02<00:02, 98.36it/s]predictive accuracy: 73.06%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:04<00:01, 98.67it/s]predictive accuracy: 72.45%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:05<00:00, 70.51it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:26<00:28, 28.75s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:53<00:00, 28.43s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 70.38%\n",
      " 24%|█████████▉                                | 95/400 [00:02<00:05, 51.17it/s]predictive accuracy: 74.07%\n",
      " 50%|████████████████████▌                    | 200/400 [00:05<00:03, 54.84it/s]predictive accuracy: 70.32%\n",
      " 74%|██████████████████████████████▎          | 296/400 [00:08<00:01, 53.65it/s]predictive accuracy: 67.77%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 34.82it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:24<00:27, 27.91s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:49<00:00, 27.35s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.46%\n",
      " 24%|██████████▎                               | 98/400 [00:03<00:08, 34.78it/s]predictive accuracy: 81.58%\n",
      " 50%|████████████████████▌                    | 200/400 [00:08<00:05, 35.62it/s]predictive accuracy: 80.25%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:12<00:03, 31.40it/s]predictive accuracy: 79.03%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:15<00:00, 25.14it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #2\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:31<00:30, 30.16s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [02:02<00:00, 30.66s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 64.57%\n",
      " 24%|██████████                                | 96/400 [00:02<00:05, 54.67it/s]predictive accuracy: 66.48%\n",
      " 50%|████████████████████▍                    | 199/400 [00:05<00:03, 56.56it/s]predictive accuracy: 66.32%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:08<00:01, 52.14it/s]predictive accuracy: 66.22%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 35.11it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.12s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:56<00:00, 29.10s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 64.45%\n",
      " 24%|██████████                                | 96/400 [00:03<00:06, 50.59it/s]predictive accuracy: 75.60%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:03, 52.32it/s]predictive accuracy: 73.56%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:08<00:02, 45.24it/s]predictive accuracy: 72.46%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:12<00:00, 32.50it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:36<00:32, 32.07s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [02:09<00:00, 32.46s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 65.48%\n",
      " 25%|██████████▍                               | 99/400 [00:02<00:04, 72.53it/s]predictive accuracy: 79.12%\n",
      " 49%|███████████████████▉                     | 195/400 [00:04<00:02, 74.94it/s]predictive accuracy: 77.03%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:06<00:01, 72.87it/s]predictive accuracy: 76.28%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:07<00:00, 50.16it/s]\n",
      "Trial completed!\n",
      "\n",
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 3 independent trials.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:26<00:28, 28.48s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:56<00:00, 29.02s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.16%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:06, 48.64it/s]predictive accuracy: 67.71%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:03, 56.29it/s]predictive accuracy: 67.94%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:08<00:02, 45.34it/s]predictive accuracy: 68.11%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 35.92it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:20<00:25, 25.96s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:49<00:00, 27.25s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.12%\n",
      " 24%|██████████                                | 96/400 [00:02<00:06, 50.57it/s]predictive accuracy: 67.82%\n",
      " 50%|████████████████████▎                    | 198/400 [00:05<00:03, 52.29it/s]predictive accuracy: 71.00%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:08<00:01, 57.34it/s]predictive accuracy: 76.30%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 34.87it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.93s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:53<00:00, 28.30s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.12%\n",
      " 25%|██████████▍                               | 99/400 [00:03<00:08, 35.73it/s]predictive accuracy: 72.21%\n",
      " 49%|████████████████████▏                    | 197/400 [00:06<00:05, 39.26it/s]predictive accuracy: 75.97%\n",
      " 75%|██████████████████████████████▋          | 299/400 [00:10<00:02, 34.64it/s]predictive accuracy: 79.99%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:13<00:00, 28.80it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #1\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:17<00:25, 25.92s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:45<00:00, 26.39s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 58.12%\n",
      " 25%|██████████▍                               | 99/400 [00:02<00:04, 67.76it/s]predictive accuracy: 64.59%\n",
      " 50%|████████████████████▍                    | 199/400 [00:04<00:03, 56.39it/s]predictive accuracy: 65.06%\n",
      " 75%|██████████████████████████████▋          | 299/400 [00:07<00:01, 54.08it/s]predictive accuracy: 65.27%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 39.57it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:26<00:28, 28.82s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:56<00:00, 29.07s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 56.12%\n",
      " 24%|██████████                                | 96/400 [00:02<00:06, 44.26it/s]predictive accuracy: 73.10%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:03, 58.65it/s]predictive accuracy: 75.40%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:07<00:01, 59.04it/s]predictive accuracy: 76.90%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 39.71it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:18<00:26, 26.76s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:45<00:00, 26.34s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 57.57%\n",
      " 24%|██████████▎                               | 98/400 [00:01<00:05, 56.35it/s]predictive accuracy: 74.57%\n",
      " 48%|███████████████████▉                     | 194/400 [00:04<00:03, 55.22it/s]predictive accuracy: 78.74%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:08<00:03, 27.06it/s]predictive accuracy: 79.32%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 34.27it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #2\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:29<00:29, 29.62s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:52<00:00, 28.20s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.45%\n",
      " 24%|██████████▎                               | 98/400 [00:01<00:04, 70.91it/s]predictive accuracy: 66.65%\n",
      " 50%|████████████████████▍                    | 199/400 [00:04<00:03, 60.02it/s]predictive accuracy: 66.90%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:07<00:01, 54.54it/s]predictive accuracy: 66.93%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 39.80it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:27<00:28, 28.64s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:57<00:00, 29.28s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.39%\n",
      " 24%|██████████▏                               | 97/400 [00:01<00:03, 76.48it/s]predictive accuracy: 69.20%\n",
      " 49%|███████████████████▉                     | 195/400 [00:03<00:02, 82.03it/s]predictive accuracy: 73.26%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:05<00:01, 57.11it/s]predictive accuracy: 77.24%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:08<00:00, 46.78it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:14<00:23, 23.72s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:43<00:00, 25.80s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.45%\n",
      " 24%|██████████                                | 96/400 [00:01<00:04, 64.51it/s]predictive accuracy: 72.40%\n",
      " 50%|████████████████████▍                    | 199/400 [00:04<00:03, 56.12it/s]predictive accuracy: 74.08%\n",
      " 75%|██████████████████████████████▋          | 299/400 [00:07<00:03, 29.34it/s]predictive accuracy: 76.05%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 37.09it/s]\n",
      "Trial completed!\n",
      "\n",
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 3 independent trials.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:29<00:29, 29.39s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:53<00:00, 28.36s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 69.03%\n",
      " 24%|██████████                                | 96/400 [00:02<00:04, 67.46it/s]predictive accuracy: 67.31%\n",
      " 49%|███████████████████▉                     | 195/400 [00:04<00:03, 63.68it/s]predictive accuracy: 67.28%\n",
      " 73%|██████████████████████████████           | 293/400 [00:07<00:01, 68.96it/s]predictive accuracy: 67.09%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:09<00:00, 42.57it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:14<00:25, 25.63s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:44<00:00, 26.22s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 67.04%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:06, 48.11it/s]predictive accuracy: 66.89%\n",
      " 50%|████████████████████▎                    | 198/400 [00:04<00:03, 58.02it/s]predictive accuracy: 67.06%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:06<00:01, 85.29it/s]predictive accuracy: 66.70%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:08<00:00, 47.51it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.86%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.49s/it]predictive accuracy: 89.73%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:52<00:00, 28.09s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 69.42%\n",
      " 24%|█████████▊                                | 94/400 [00:01<00:04, 76.08it/s]predictive accuracy: 77.19%\n",
      " 49%|████████████████████▏                    | 197/400 [00:03<00:03, 50.84it/s]predictive accuracy: 78.01%\n",
      " 75%|██████████████████████████████▋          | 299/400 [00:07<00:02, 38.54it/s]predictive accuracy: 78.13%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 38.92it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #1\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.69s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:51<00:00, 27.99s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 65.24%\n",
      " 25%|██████████▎                              | 100/400 [00:01<00:04, 68.27it/s]predictive accuracy: 59.63%\n",
      " 50%|████████████████████▌                    | 200/400 [00:03<00:02, 72.94it/s]predictive accuracy: 58.77%\n",
      " 74%|██████████████████████████████▏          | 295/400 [00:05<00:01, 77.69it/s]predictive accuracy: 58.65%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:07<00:00, 51.70it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:24<00:28, 28.40s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:51<00:00, 28.00s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 60.19%\n",
      " 23%|█████████▊                                | 93/400 [00:01<00:03, 93.45it/s]predictive accuracy: 58.17%\n",
      " 48%|███████████████████▌                     | 191/400 [00:02<00:02, 84.88it/s]predictive accuracy: 57.75%\n",
      " 75%|██████████████████████████████▋          | 299/400 [00:04<00:01, 55.94it/s]predictive accuracy: 57.03%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:07<00:00, 50.62it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.82%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.81s/it]predictive accuracy: 89.70%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:50<00:00, 27.73s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 63.28%\n",
      " 24%|██████████                                | 96/400 [00:02<00:06, 48.75it/s]predictive accuracy: 70.31%\n",
      " 50%|████████████████████▎                    | 198/400 [00:05<00:05, 38.14it/s]predictive accuracy: 69.94%\n",
      " 74%|██████████████████████████████▎          | 296/400 [00:08<00:03, 32.85it/s]predictive accuracy: 68.76%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:12<00:00, 32.29it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #2\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:25<00:28, 28.21s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:48<00:00, 27.18s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 66.21%\n",
      " 24%|██████████▎                               | 98/400 [00:02<00:04, 64.91it/s]predictive accuracy: 68.48%\n",
      " 49%|████████████████████                     | 196/400 [00:04<00:04, 48.18it/s]predictive accuracy: 68.67%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:07<00:01, 54.83it/s]predictive accuracy: 68.80%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 38.41it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:24<00:27, 27.86s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:52<00:00, 28.22s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 69.88%\n",
      " 25%|██████████▍                               | 99/400 [00:02<00:05, 57.87it/s]predictive accuracy: 65.81%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:03, 57.78it/s]predictive accuracy: 64.77%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:08<00:01, 50.86it/s]predictive accuracy: 64.26%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 36.12it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 90.87%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:18<00:24, 24.95s/it]predictive accuracy: 89.72%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:46<00:00, 26.69s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.36%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:06, 48.75it/s]predictive accuracy: 68.56%\n",
      " 49%|████████████████████▏                    | 197/400 [00:05<00:04, 42.69it/s]predictive accuracy: 70.14%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:09<00:02, 41.22it/s]predictive accuracy: 69.88%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:12<00:00, 31.57it/s]\n",
      "Trial completed!\n",
      "\n",
      "\n",
      "Reading/Generating the dataset WEBSPAM\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "X is either low-dimensional or not very sparse, so converting to a numpy array\n",
      "Details about dataset: Total Datapoints: 126185, Dimensions: 128, num classes: 2\n",
      "\n",
      "Bayesian logistic regression experiment.\n",
      "Inference via MFVI_SELECTION on webspam data over 3 independent trials.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Running mfvi_selection\n",
      "\n",
      "Trial #0\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:23<00:27, 27.82s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:51<00:00, 27.76s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.11%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:04, 62.11it/s]predictive accuracy: 63.16%\n",
      " 49%|████████████████████▏                    | 197/400 [00:04<00:03, 60.69it/s]predictive accuracy: 55.92%\n",
      " 74%|██████████████████████████████▎          | 296/400 [00:07<00:01, 66.36it/s]predictive accuracy: 55.79%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:09<00:00, 41.95it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:18<00:26, 26.73s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:48<00:00, 27.14s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.11%\n",
      " 25%|██████████▎                              | 100/400 [00:02<00:05, 51.61it/s]predictive accuracy: 67.21%\n",
      " 50%|████████████████████▎                    | 198/400 [00:05<00:03, 53.56it/s]predictive accuracy: 67.75%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:07<00:01, 52.67it/s]predictive accuracy: 68.44%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 37.42it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.33%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:24<00:27, 27.86s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:53<00:00, 28.28s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 39.11%\n",
      " 24%|██████████▏                               | 97/400 [00:01<00:04, 75.75it/s]predictive accuracy: 69.00%\n",
      " 50%|████████████████████▍                    | 199/400 [00:03<00:03, 59.10it/s]predictive accuracy: 64.85%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:06<00:03, 32.43it/s]predictive accuracy: 62.17%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 38.21it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #1\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:28<00:29, 29.47s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:57<00:00, 29.43s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 57.85%\n",
      " 24%|█████████▉                                | 95/400 [00:02<00:04, 71.08it/s]predictive accuracy: 39.71%\n",
      " 50%|████████████████████▍                    | 199/400 [00:05<00:03, 59.39it/s]predictive accuracy: 34.59%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:07<00:01, 61.43it/s]predictive accuracy: 34.48%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:10<00:00, 39.15it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:21<00:26, 26.48s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:49<00:00, 27.26s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 62.02%\n",
      " 24%|██████████▎                               | 98/400 [00:02<00:06, 48.29it/s]predictive accuracy: 71.29%\n",
      " 48%|███████████████████▉                     | 194/400 [00:05<00:02, 70.30it/s]predictive accuracy: 71.85%\n",
      " 74%|██████████████████████████████▏          | 295/400 [00:07<00:02, 51.81it/s]predictive accuracy: 72.21%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 36.35it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.68%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:26<00:28, 28.41s/it]predictive accuracy: 90.38%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:55<00:00, 28.91s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 61.78%\n",
      " 24%|██████████                                | 96/400 [00:02<00:05, 53.12it/s]predictive accuracy: 69.84%\n",
      " 49%|████████████████████                     | 196/400 [00:05<00:04, 40.99it/s]predictive accuracy: 70.00%\n",
      " 75%|██████████████████████████████▊          | 300/400 [00:08<00:02, 37.83it/s]predictive accuracy: 70.04%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:12<00:00, 33.13it/s]\n",
      "Trial completed!\n",
      "\n",
      "Trial #2\n",
      "Coreset/Subset with 10 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:21<00:27, 27.09s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:51<00:00, 27.88s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 66.92%\n",
      " 24%|█████████▉                                | 95/400 [00:01<00:04, 71.15it/s]predictive accuracy: 64.34%\n",
      " 49%|███████████████████▉                     | 195/400 [00:03<00:03, 63.58it/s]predictive accuracy: 58.59%\n",
      " 74%|██████████████████████████████▎          | 296/400 [00:05<00:01, 79.99it/s]predictive accuracy: 49.88%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:08<00:00, 48.39it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 40 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:26<00:28, 28.45s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:55<00:00, 28.78s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.04%\n",
      " 24%|██████████▏                               | 97/400 [00:02<00:04, 61.58it/s]predictive accuracy: 67.28%\n",
      " 48%|███████████████████▉                     | 194/400 [00:04<00:03, 66.24it/s]predictive accuracy: 69.38%\n",
      " 74%|██████████████████████████████▍          | 297/400 [00:06<00:01, 65.67it/s]predictive accuracy: 69.62%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:09<00:00, 42.23it/s]\n",
      "Trial completed!\n",
      "\n",
      "Coreset/Subset with 100 datapoints\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]predictive accuracy: 84.56%\n",
      " 75%|█████████████████████████████████▊           | 3/4 [01:12<00:24, 24.38s/it]predictive accuracy: 90.42%\n",
      "100%|█████████████████████████████████████████████| 4/4 [01:40<00:00, 25.14s/it]\n",
      "/home/studio-lab-user/Blackbox-Coresets-VI/psvi/inference/utils.py:640: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  outputs_prob = softmax_fn(output)\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]predictive accuracy: 68.06%\n",
      " 25%|██████████▍                               | 99/400 [00:02<00:06, 50.10it/s]predictive accuracy: 68.02%\n",
      " 50%|████████████████████▌                    | 200/400 [00:05<00:04, 42.43it/s]predictive accuracy: 68.35%\n",
      " 74%|██████████████████████████████▌          | 298/400 [00:08<00:02, 41.47it/s]predictive accuracy: 67.50%\n",
      "100%|█████████████████████████████████████████| 400/400 [00:11<00:00, 34.10it/s]\n",
      "Trial completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for this_selection in selection_method:\n",
    "    for lr in lr_list:\n",
    "        !python3 psvi_experiments.py --datasets \"webspam\" \\\n",
    "        --architecture \"logistic_regression\" --n_hidden 100 --methods \"mfvi_selection\"\\\n",
    "        --data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "        --results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "        --log_every 100 --num_epochs 200 --mc_samples 256 --inner_it 20 --lr0net {lr}\\\n",
    "        --coreset_sizes 10 40 100 --init_at \"subsample\"\\\n",
    "        --save_new_folder\\\n",
    "        --mfvi_selection_method {this_selection} --num_trials 3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174dde74-0949-4ca8-8858-fece845837ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_method = [\n",
    "    \"kmeans\", \"scored_kmeans_forgetting\"\n",
    "]\n",
    "\n",
    "lr_list = [1e-2, 1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38257ed3-fc8b-4a04-be96-efcd96358f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for this_selection in selection_method:\n",
    "    for lr in lr_list:\n",
    "        !python3 psvi_experiments.py --datasets \"MNIST\" \\\n",
    "        --architecture \"lenet\" --n_hidden 100 --methods \"mfvi_selection\"\\\n",
    "        --data_folder \"/home/studio-lab-user/all_data/vi_data\" \\\n",
    "        --results_folder \"/home/studio-lab-user/all_data/vi_result\" \\\n",
    "        --log_every 100 --num_epochs 200 --mc_samples 256 --inner_it 20 --lr0net {lr}\\\n",
    "        --coreset_sizes 10 40 100 --init_at \"subsample\"\\\n",
    "        --save_new_folder\\\n",
    "        --mfvi_selection_method {this_selection} --num_trials 3 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c9916ed-73a3-41c8-88e5-3257ac03fc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1355, -0.2142,  0.1337,  ..., -0.4177, -0.1291,  1.0000],\n",
       "         [ 0.2366, -0.0285, -0.0551,  ..., -0.0268, -0.4718,  1.0000],\n",
       "         [ 0.1945, -0.0089,  0.0135,  ..., -0.0408, -0.5287,  1.0000],\n",
       "         ...,\n",
       "         [-0.1364, -0.1582,  0.0703,  ..., -0.1382, -0.3796,  1.0000],\n",
       "         [ 0.1848, -0.0526,  0.0829,  ...,  0.0579, -0.5467,  1.0000],\n",
       "         [ 0.1889,  0.0078, -0.0184,  ...,  0.0178, -0.5397,  1.0000]]),\n",
       " tensor([1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "         1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "         1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1.,\n",
       "         0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "         1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
       "         1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "         0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "         1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0.,\n",
       "         1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "         1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "         1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "         1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "         1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "         1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         1., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 1.]),\n",
       " tensor([[ 0.0374, -0.1474,  0.1871,  ...,  0.3965,  0.1226,  1.0000],\n",
       "         [ 0.3132, -0.0624, -0.0585,  ..., -0.0861, -0.4071,  1.0000],\n",
       "         [ 0.0795, -0.1782, -0.0496,  ...,  0.1768, -0.5454,  1.0000],\n",
       "         ...,\n",
       "         [-0.0234, -0.0781,  0.0995,  ...,  0.0350, -0.2275,  1.0000],\n",
       "         [-0.1828,  0.1394,  0.0394,  ...,  0.0293, -0.4608,  1.0000],\n",
       "         [ 0.0532, -0.1878, -0.1251,  ...,  0.0176, -0.3791,  1.0000]]),\n",
       " tensor([0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "         1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1.,\n",
       "         1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "         1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 1., 1., 0., 0.]),\n",
       " 400,\n",
       " 11,\n",
       " <psvi.experiments.experiments_utils.SynthDataset at 0x7f6ca3add190>,\n",
       " <psvi.experiments.experiments_utils.SynthDataset at 0x7f6ca3070880>,\n",
       " 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_dataset(\"phishing\", method_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a23746e8-e507-4e82-bc5e-df66041386cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'rec_dd' on <module '__main__'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_79/895098238.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfull_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcar_pickle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfull_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcar_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcar_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'rec_dd' on <module '__main__'>"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle\n",
    "results_folder = \"/home/studio-lab-user/all_data/vi_result\"\n",
    "result_file = 'results.pk'\n",
    "full_fname = os.path.join(results_folder, result_file)\n",
    "car_pickle = open (full_fname, \"rb\")\n",
    "car_contents = pickle.load(car_pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09370352-2d0d-4927-a72c-6becdbb692f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 1\n",
      "Number of items: 2\n",
      "Number of items: 3\n",
      "Number of items: 4\n"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "    !python3 add_numbers.py -n {x}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492aa796-a200-4d73-a0a4-11ee14a8ffd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
